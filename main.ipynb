{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, layer, pos):\n",
    "        self.layer = layer\n",
    "        self.pos = pos\n",
    "        self.value = 0\n",
    "        self.weights: List[float] = []\n",
    "        self.new_weights: List[float] = []\n",
    "        self.prev_neurons: List[Neuron] = []\n",
    "        self.next_neurons: List[Neuron] = []\n",
    "        self.need_activation: bool = True\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        if not self.prev_neurons:\n",
    "            return f\"\"\"Neuron ({self.layer},{self.pos})\n",
    "x -> {self.value}\n",
    "\"\"\"\n",
    "        elif not self.next_neurons:\n",
    "            return f\"\"\"Neuron ({self.layer},{self.pos})\n",
    "x -> {self.activate()}\n",
    "Pesos -> {self.weights}\n",
    "Bias -> {self.bias}\n",
    "\"\"\"\n",
    "        else:\n",
    "            return f\"\"\"Neuron ({self.layer},{self.pos})\n",
    "x -> {self.activate()}\n",
    "Pesos -> {self.weights}\n",
    "Bias -> {self.bias}\n",
    "\"\"\"\n",
    "\n",
    "    def activate(self):\n",
    "        return 1 / (1 + math.exp(-self.value))\n",
    "\n",
    "    def derivative(self):\n",
    "        activate = self.activate()  # Calcular una sola vez\n",
    "        return activate * (1 - activate)\n",
    "\n",
    "    def calculate_value(self):\n",
    "        for prev_neuron, weight in zip(self.prev_neurons, self.weights):\n",
    "            if not prev_neuron.need_activation:\n",
    "                self.value += prev_neuron.value * weight\n",
    "            else:\n",
    "                self.value += prev_neuron.activate() * weight\n",
    "        self.value += self.bias\n",
    "\n",
    "    def calculate_new_weight(self, label, learning_rate):\n",
    "        if not self.next_neurons:  # Capa de salida\n",
    "            self.delta = (self.activate() - label) * self.derivative()\n",
    "        else:\n",
    "            next_sum = 0\n",
    "            for next_neuron in self.next_neurons:\n",
    "                for prev_neuron, next_weight in zip(\n",
    "                    next_neuron.prev_neurons, next_neuron.weights\n",
    "                ):\n",
    "                    if self == prev_neuron:\n",
    "                        next_sum += next_neuron.delta * next_weight\n",
    "                        break\n",
    "            self.delta = next_sum * self.derivative()\n",
    "\n",
    "        new_weights = [\n",
    "            weight - (learning_rate * self.delta * prev_neuron.activate())\n",
    "            for weight, prev_neuron in zip(self.weights, self.prev_neurons)\n",
    "        ]\n",
    "        self.new_weights = new_weights\n",
    "        self.new_bias = self.bias - (learning_rate * self.delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):  # nn = NeuralNetwork([5, 3, 2])\n",
    "        self.layers: List[List[Neuron]] = []\n",
    "        self.add_layers(layers)\n",
    "        self.setup()\n",
    "\n",
    "    def __repr__(self):\n",
    "        string = \"\"\n",
    "        for layer in self.layers:\n",
    "            for neuron in layer:\n",
    "                string += neuron.__repr__()\n",
    "            string += \"\\n\"\n",
    "        return string\n",
    "\n",
    "    def add_layers(self, layers):  # Agrega neuronas sin parametros\n",
    "        for i, layer in enumerate(layers, start=1):\n",
    "            self.layers.append([Neuron(i, j + 1) for j in range(layer)])\n",
    "\n",
    "    def setup(self):  # Agrega listas de pesos, sesgos, neuronas previas y neuronas siguientes\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            for neuron in layer:\n",
    "                if i == 0:  # Capa de entrada\n",
    "                    neuron.next_neurons = self.layers[i + 1]\n",
    "                elif i == len(self.layers) - 1:  # Capas salida\n",
    "                    neuron.weights = [0.10 * np.random.randn() for _ in range(len(self.layers[i - 1]))]\n",
    "                    neuron.bias = 1\n",
    "                    neuron.prev_neurons = self.layers[i - 1]\n",
    "                else:  # Capa ocultas\n",
    "                    neuron.weights = [0.10 * np.random.randn() for _ in range(len(self.layers[i - 1]))]\n",
    "                    neuron.bias = 1\n",
    "                    neuron.prev_neurons = self.layers[i - 1]\n",
    "                    neuron.next_neurons = self.layers[i + 1]\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # outputs = []\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                for neuron, x in zip(layer, inputs):\n",
    "                    neuron.value = x\n",
    "                    neuron.need_activation = False\n",
    "            else:\n",
    "                for neuron in layer:\n",
    "                    neuron.calculate_value()\n",
    "                    if i == len(self.layers) - 1:\n",
    "                        output = neuron.activate()\n",
    "        return output\n",
    "\n",
    "    def update_weights(self, label, lr):\n",
    "        for layer in reversed(self.layers[1:]):\n",
    "            for neuron in layer:\n",
    "                neuron.calculate_new_weight(label, lr)\n",
    "\n",
    "        for layer in self.layers[1:]:\n",
    "            for neuron in layer:\n",
    "                neuron.weights = neuron.new_weights\n",
    "                neuron.bias = neuron.new_bias\n",
    "\n",
    "    def reset_values(self):\n",
    "        for layer in self.layers:\n",
    "            for neuron in layer:\n",
    "                neuron.value = 0\n",
    "\n",
    "    def train(self, X, y, n_epochs, lr=0.1):\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            correct = 0\n",
    "            error = 0\n",
    "            for x, label in zip(X, y):\n",
    "                output = self.predict(x)\n",
    "                predicted = 0 if output < 0.5 else 1\n",
    "                correct += int(predicted == label)\n",
    "                error += (output - label) ** 2.0\n",
    "                self.update_weights(label, lr)\n",
    "                self.reset_values()\n",
    "            accuracy = 100 * correct / len(X)\n",
    "            loss = error / len(X)\n",
    "            if epoch % 50 == 0:\n",
    "                print(\"Epoch {}/{}, Loss: {:.8f}, Accuracy: {:.3f}\".format(epoch, n_epochs, loss, accuracy))\n",
    "        # print(f\"Epochs {n_epochs}, Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([13, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos desde dataset.csv\n",
    "dataset_df = pd.read_csv(\"dataset.csv\", usecols=[i for i in range(1, 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01020</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03440</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60400</td>\n",
       "      <td>0.494</td>\n",
       "      <td>199413</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>-15.236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>86.468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.678</td>\n",
       "      <td>392893</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-11.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>174.004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.584</td>\n",
       "      <td>274404</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-3.501</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>74.976</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.08770</td>\n",
       "      <td>0.894</td>\n",
       "      <td>182182</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>-2.663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>110.041</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.00857</td>\n",
       "      <td>0.637</td>\n",
       "      <td>207200</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>-2.467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>150.082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.557</td>\n",
       "      <td>185600</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>-2.735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>150.011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.446</td>\n",
       "      <td>204520</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>-6.221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>190.013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0          0.01020         0.833       204600   0.434          0.021900    2   \n",
       "1          0.19900         0.743       326933   0.359          0.006110    1   \n",
       "2          0.03440         0.838       185707   0.412          0.000234    2   \n",
       "3          0.60400         0.494       199413   0.338          0.510000    5   \n",
       "4          0.18000         0.678       392893   0.561          0.512000    5   \n",
       "...            ...           ...          ...     ...               ...  ...   \n",
       "2012       0.00106         0.584       274404   0.932          0.002690    1   \n",
       "2013       0.08770         0.894       182182   0.892          0.001670    1   \n",
       "2014       0.00857         0.637       207200   0.935          0.003990    0   \n",
       "2015       0.00164         0.557       185600   0.992          0.677000    1   \n",
       "2016       0.00281         0.446       204520   0.915          0.000039    9   \n",
       "\n",
       "      liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n",
       "0       0.1650    -8.795     1       0.4310  150.062             4.0    0.286   \n",
       "1       0.1370   -10.401     1       0.0794  160.083             4.0    0.588   \n",
       "2       0.1590    -7.148     1       0.2890   75.044             4.0    0.173   \n",
       "3       0.0922   -15.236     1       0.0261   86.468             4.0    0.230   \n",
       "4       0.4390   -11.648     0       0.0694  174.004             4.0    0.904   \n",
       "...        ...       ...   ...          ...      ...             ...      ...   \n",
       "2012    0.1290    -3.501     1       0.3330   74.976             4.0    0.211   \n",
       "2013    0.0528    -2.663     1       0.1310  110.041             4.0    0.867   \n",
       "2014    0.2140    -2.467     1       0.1070  150.082             4.0    0.470   \n",
       "2015    0.0913    -2.735     1       0.1330  150.011             4.0    0.623   \n",
       "2016    0.2180    -6.221     1       0.1410  190.013             4.0    0.402   \n",
       "\n",
       "      target  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "2012       0  \n",
       "2013       0  \n",
       "2014       0  \n",
       "2015       0  \n",
       "2016       0  \n",
       "\n",
       "[2017 rows x 14 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenamiento\n",
    "dataset_df_copy = dataset_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrada y etiquetas\n",
    "n_columns = len(dataset_df_copy.columns)\n",
    "data_input = dataset_df_copy.iloc[:, 0 : n_columns - 1]\n",
    "data_label = dataset_df_copy.iloc[:, n_columns - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "2012    0\n",
       "2013    1\n",
       "2014    0\n",
       "2015    1\n",
       "2016    0\n",
       "Name: target, Length: 2017, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion\n",
    "norm_cols = [\"duration_ms\", \"key\", \"loudness\", \"tempo\", \"time_signature\"]\n",
    "for feature_name in data_input.columns:\n",
    "    if feature_name in norm_cols:\n",
    "        min_val = data_input[feature_name].max()\n",
    "        max_val = data_input[feature_name].min()\n",
    "        data_input[feature_name] = (data_input[feature_name] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.787685</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.206709</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.381310</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.810617</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.250686</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.579733</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.813513</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.212748</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.592231</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.818356</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.093108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.684065</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.584067</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.265569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.474311</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.791610</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.130985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.719249</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.610849</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.204666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.579412</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.686881</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.429186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.600815</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.775055</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.260929</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.6170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.826722</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.185910</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.497603</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  duration_ms  energy  instrumentalness  \\\n",
       "0         0.379000         0.534     0.787685   0.508          0.000000   \n",
       "1         0.765000         0.767     0.810617   0.445          0.000727   \n",
       "2         0.573000         0.498     0.813513   0.467          0.000000   \n",
       "3         0.168000         0.859     0.818356   0.756          0.000046   \n",
       "4         0.723000         0.688     0.584067   0.421          0.625000   \n",
       "...            ...           ...          ...     ...               ...   \n",
       "2012      0.000797         0.480     0.791610   0.826          0.000001   \n",
       "2013      0.074000         0.912     0.610849   0.781          0.762000   \n",
       "2014      0.912000         0.399     0.686881   0.307          0.623000   \n",
       "2015      0.031300         0.515     0.775055   0.902          0.000000   \n",
       "2016      0.017900         0.512     0.826722   0.587          0.000000   \n",
       "\n",
       "           key  liveness  loudness  mode  speechiness     tempo  \\\n",
       "0     0.818182    0.0867  0.206709     1       0.0322  0.381310   \n",
       "1     0.454545    0.0897  0.250686     1       0.0328  0.579733   \n",
       "2     0.909091    0.1030  0.212748     1       0.0300  0.592231   \n",
       "3     0.272727    0.1630  0.093108     0       0.0643  0.684065   \n",
       "4    -0.000000    0.0734  0.265569     0       0.0445  0.474311   \n",
       "...        ...       ...       ...   ...          ...       ...   \n",
       "2012  1.000000    0.1250  0.130985     1       0.0397  0.719249   \n",
       "2013  0.363636    0.3480  0.204666     0       0.0444  0.579412   \n",
       "2014  0.909091    0.1150  0.429186     1       0.0347  0.600815   \n",
       "2015  0.454545    0.0930  0.134858     0       0.3830  0.260929   \n",
       "2016  0.909091    0.1070  0.185910     1       0.0291  0.497603   \n",
       "\n",
       "      time_signature  valence  \n",
       "0               0.25   0.4070  \n",
       "1               0.25   0.3750  \n",
       "2               0.25   0.4020  \n",
       "3               0.25   0.9130  \n",
       "4               0.25   0.6300  \n",
       "...              ...      ...  \n",
       "2012            0.25   0.7010  \n",
       "2013            0.25   0.8910  \n",
       "2014            0.25   0.0621  \n",
       "2015           -0.00   0.6170  \n",
       "2016            0.25   0.3130  \n",
       "\n",
       "[2017 rows x 13 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division de datos\n",
    "training_percent = 0.7\n",
    "n_rows = len(dataset_df_copy.index)\n",
    "n_train = round(training_percent * n_rows)\n",
    "n_test = n_rows - n_train\n",
    "\n",
    "X_train = data_input.iloc[0:n_train]\n",
    "y_train = data_label.iloc[0:n_train]\n",
    "X_test = data_input.iloc[n_test:]\n",
    "y_test = data_label.iloc[n_test:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1407    0\n",
       "1408    1\n",
       "1409    0\n",
       "1410    1\n",
       "1411    1\n",
       "Name: target, Length: 1412, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.22460573, Accuracy: 63.952\n",
      "Epoch 100/100, Loss: 0.21891022, Accuracy: 64.873\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "nn.train(X_train.values, y_train.values, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xor_nn = NeuralNetwork([2, 2, 1])\n",
    "\n",
    "X = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "]\n",
    "\n",
    "y = [0, 1, 1, 0]\n",
    "\n",
    "n_epochs = 100_000\n",
    "\n",
    "nn.train(X, y, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1fbe745135a03aee40870fc7176212f85e41d43b6d36926e3888d80b670d5f61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
